---
title: 特征问题的解法——向量迭代法（一）
date: 2024-04-06 18:55:11
categories:
- [2.数值计算,2.特征问题的解法]
tags:
- 特征值计算
- 模态计算
- 幂法
- 逆幂法
- 向量迭代法
- 逆迭代法
mathjax: true
---

## 前言

在工程中，我们经常需要对模型进行模态分析，以确定模型的模态频率和振型。

模态分析本质上是求解特征值问题
$$
{\rm K \phi} = \lambda {\rm M \phi} \tag{1}
$$
特别是求解最小特征值 $\lambda_1, \dots, \lambda_p$ 及其特征向量 $\phi_1, \dots, \phi_p$ 。

常用的特征值求解算法可分为四类，对应于求解算法利用的基本性质。

第一类是向量迭代法(Vector Iteration Method)，又称为幂法(Power Iteration Method)，利用的基本性质是
$$
{\rm K \phi_i} = \lambda_i{\rm M \phi_i} \tag{2}
$$

第二类为变换法，利用的基本性质是
$$
{\rm \Phi^T K \Phi} = {\rm \Lambda}  \tag{3}
$$
$$
{\rm \Phi^T M \Phi} = {\rm I}  \tag{4}
$$
其中， ${\rm \Phi} = \left[ {\rm \phi_i, \dots, \phi_n} \right]$ 和 ${\rm \Lambda} = {\rm diag(\lambda_i)}, i=1,\dots,n$ 。

第三类为多项式迭代法，利用的基本性质是
$$
p(\lambda_i) = 0 \tag{5}
$$
其中，
$$
p(\lambda) = {\rm det(K - \lambda M)} \tag{6}
$$

第四类求解算法利用特征多项式的 Sturm 序列性质
$$
p(\lambda) = {\rm det(K - \lambda M)} \tag{7}
$$
$$
p^{(r)}(\lambda^{(r)}) = {\rm det(K^{(r)} - \lambda^{(r)}M^{(r)})}; \quad r=1,\dots,n-1  \tag{8}
$$
其中， $p^{(r)}(\lambda^{(r)})$ 是对应于${\rm K \phi = \lambda M \phi}$ 的第 $r$ 个相伴约束问题的特征多项式。

在四类求解方法中，每一类都提出了许多算法。

在学习具体算法前，需要认识到，求解算法应具有迭代性质，
因为求解特征问题 ${\rm K \phi = \lambda M \phi}$ 就等价于计算多项式 $p(\lambda)$ 的根，它的阶等于 ${\rm K}$ 和 ${\rm M}$ 的阶。

接下来开始介绍第一类方法：向量迭代法。而在介绍向量迭代法之前，先尝试理解其基本思想。

## 基本思想

假设向量 ${\rm A}$ 有 $n$ 个线性无关的特征向量 $\mathit{x_1, \dots, x_n}$ ，且相应的特征值满足
$$
|\lambda_1| > |\lambda_2| \geq \dots \geq |\lambda_n|
$$

给定一个任意向量 $\mathit{v}_0$ ，假设
$$
\mathit{v}_0 = \alpha_1 \mathit{x}_1 + \dots + \alpha_n \mathit{x}_n
$$

将 ${\rm A}$ 作用于该向量，有
$$
\mathbf{A} \mathit{v}_0 = \alpha_1 \lambda_1 \mathit{x}_1 + \alpha_2 \lambda_2 \mathit{x}_2 + \dots + \alpha_n \lambda_n \mathit{x}_n \\
\mathbf{A}^2 \mathit{v}_0 = \alpha_1 \lambda_1^2 \mathit{x}_1 + \alpha_2 \lambda_2^2 \mathit{x}_2 + \dots + \alpha_n \lambda_n^2 \mathit{x}_n
$$

且一般地，
$$
\mathbf{A}^k \mathit{v}_0 = \alpha_1 \lambda_1^k \mathit{x}_1 + \alpha_2 \lambda_2^k \mathit{x}_2 + \dots + \alpha_n \lambda_n^k \mathit{x}_n  \tag{9}
$$

若定义
$$
\mathit{v}_k = \mathbf{A}^k \mathit{v}_0, \quad k=1, 2, \dots
$$

则
$$
\frac{1}{\lambda_1^k} \mathit{v}_k = \alpha_1 \mathit{x}_1 + \alpha_2 (\frac{\lambda_2}{\lambda_1})^k \mathit{x}_2 + \dots + \alpha_2 (\frac{\lambda_n}{\lambda_1})^k \mathit{x}_n \tag{10}
$$

由于
$$
\left| \frac{\lambda_i}{\lambda_1} \right| < 1, \quad, i=2,3,\dots,n
$$

由此得到：
$$
\frac{1}{\lambda_1^k} \mathit{v}_k \rightarrow \alpha_1 \mathit{x}_1, \quad k \rightarrow \infty
$$

因此，若 $\alpha_1 \neq 0$ ，则序列 $\{ (1/\lambda_1^k) \mathit{v}_k \}$ 收敛到 $\mathbf{A}$ 的特征向量 $\alpha_1 \mathit{x}_1$。

当然，由于 $\lambda_1$ 是未知的，所以无法计算 $\{ (1/\lambda_1^k) \mathit{v}_k \}$ 。
但好在不需要将序列 $\{ \mathit{v}_k \}$ 用 $1/\lambda_1^k$ 进行缩放。

这就是正迭代法的思想，能计算出最大的特征值。

而模态分析需要计算的是最小特征值，需要使用的是逆迭代法，即需要将 $\mathbf{A}^{-1}$ 作用在向量上。

## 向量迭代法

向量迭代法所考虑的基本关系式是
$$
{\rm K \phi} = \lambda {\rm M \phi} \tag{1}
$$

选择 $\phi$ 的一个向量 $\mathbf{x}_1$ ，对 $\lambda$ 设定一个值，令 $\lambda = 1$ 。于是，可以计算公式 (1) 的右手边，即可以计算
$$
\mathbf{R}_1 = (1)\mathbf{M x_1} \tag{11)}
$$

## 参考文献
[1]. Bathe K J. Finite element procedures[M]. Klaus-Jurgen Bathe, 2006.

[2]. 史蒂文・J.利昂著STEVENJ.LEON.线性代数[M].机械工业出版社,2015.
